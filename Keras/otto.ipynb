{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data(path, train=True):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    if train:\n",
    "        np.random.shuffle(X)  \n",
    "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "        return X, labels\n",
    "    else:\n",
    "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "        return X, ids\n",
    "\n",
    "\n",
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "\n",
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder\n",
    "\n",
    "\n",
    "def make_submission(y_prob, ids, encoder, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('id,')\n",
    "        f.write(','.join([str(i) for i in encoder.classes_]))\n",
    "        f.write('\\n')\n",
    "        for i, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([i] + [str(p) for p in probs.tolist()])\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "9 classes\n",
      "93 dims\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "X, labels = load_data('otto/train.csv', train=True)\n",
    "X, scaler = preprocess_data(X)\n",
    "y, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('otto/test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = y.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X.shape[1]\n",
    "print(dims, 'dims')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 0\n",
      "52596/52596 [==============================] - 32s - loss: 1.0228 - val_loss: 0.7169\n",
      "Epoch 1\n",
      "52596/52596 [==============================] - 34s - loss: 0.6735 - val_loss: 0.6388\n",
      "Epoch 2\n",
      "52596/52596 [==============================] - 33s - loss: 0.6259 - val_loss: 0.6030\n",
      "Epoch 3\n",
      "52596/52596 [==============================] - 31s - loss: 0.5979 - val_loss: 0.5861\n",
      "Epoch 4\n",
      "52596/52596 [==============================] - 33s - loss: 0.5804 - val_loss: 0.5689\n",
      "Epoch 5\n",
      "52596/52596 [==============================] - 35s - loss: 0.5658 - val_loss: 0.5588\n",
      "Epoch 6\n",
      "52596/52596 [==============================] - 35s - loss: 0.5532 - val_loss: 0.5479\n",
      "Epoch 7\n",
      "52596/52596 [==============================] - 34s - loss: 0.5455 - val_loss: 0.5419\n",
      "Epoch 8\n",
      "52596/52596 [==============================] - 32s - loss: 0.5347 - val_loss: 0.5432\n",
      "Epoch 9\n",
      "52596/52596 [==============================] - 34s - loss: 0.5252 - val_loss: 0.5341\n",
      "Epoch 10\n",
      "52596/52596 [==============================] - 34s - loss: 0.5210 - val_loss: 0.5276\n",
      "Epoch 11\n",
      "52596/52596 [==============================] - 34s - loss: 0.5139 - val_loss: 0.5279\n",
      "Epoch 12\n",
      "52596/52596 [==============================] - 34s - loss: 0.5075 - val_loss: 0.5233\n",
      "Epoch 13\n",
      "52596/52596 [==============================] - 35s - loss: 0.5000 - val_loss: 0.5262\n",
      "Epoch 14\n",
      "52596/52596 [==============================] - 34s - loss: 0.4964 - val_loss: 0.5198\n",
      "Epoch 15\n",
      "52596/52596 [==============================] - 34s - loss: 0.4924 - val_loss: 0.5170\n",
      "Epoch 16\n",
      "52596/52596 [==============================] - 33s - loss: 0.4902 - val_loss: 0.5176\n",
      "Epoch 17\n",
      "52596/52596 [==============================] - 33s - loss: 0.4832 - val_loss: 0.5175\n",
      "Epoch 18\n",
      "52596/52596 [==============================] - 34s - loss: 0.4806 - val_loss: 0.5136\n",
      "Epoch 19\n",
      "52596/52596 [==============================] - 34s - loss: 0.4767 - val_loss: 0.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1122bc110>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(dims, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "model.add(PReLU((512,)))\n",
    "model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, nb_classes, init='glorot_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 52596 samples, validate on 9282 samples\n",
      "Epoch 0\n",
      "52596/52596 [==============================] - 33s - loss: 0.4744 - acc: 0.8131 - val_loss: 0.5061 - val_acc: 0.8042\n",
      "Epoch 1\n",
      "52596/52596 [==============================] - 32s - loss: 0.4694 - acc: 0.8160 - val_loss: 0.5042 - val_acc: 0.8013\n",
      "Epoch 2\n",
      "52596/52596 [==============================] - 31s - loss: 0.4676 - acc: 0.8150 - val_loss: 0.5081 - val_acc: 0.8020\n",
      "Epoch 3\n",
      "52596/52596 [==============================] - 34s - loss: 0.4617 - acc: 0.8169 - val_loss: 0.5094 - val_acc: 0.8065\n",
      "Epoch 4\n",
      "52596/52596 [==============================] - 39s - loss: 0.4596 - acc: 0.8180 - val_loss: 0.5142 - val_acc: 0.8010\n",
      "Epoch 5\n",
      "52596/52596 [==============================] - 40s - loss: 0.4579 - acc: 0.8187 - val_loss: 0.5132 - val_acc: 0.8039\n",
      "Epoch 6\n",
      "52596/52596 [==============================] - 33s - loss: 0.4569 - acc: 0.8180 - val_loss: 0.5053 - val_acc: 0.8031\n",
      "Epoch 7\n",
      "52596/52596 [==============================] - 33s - loss: 0.4522 - acc: 0.8207 - val_loss: 0.5020 - val_acc: 0.8059\n",
      "Epoch 8\n",
      "52596/52596 [==============================] - 56s - loss: 0.4490 - acc: 0.8233 - val_loss: 0.5156 - val_acc: 0.8000\n",
      "Epoch 9\n",
      "52596/52596 [==============================] - 35s - loss: 0.4454 - acc: 0.8217 - val_loss: 0.5060 - val_acc: 0.8045\n",
      "Epoch 10\n",
      "52596/52596 [==============================] - 32s - loss: 0.4447 - acc: 0.8241 - val_loss: 0.5012 - val_acc: 0.8058\n",
      "Epoch 11\n",
      "52596/52596 [==============================] - 36s - loss: 0.4419 - acc: 0.8241 - val_loss: 0.5015 - val_acc: 0.8049\n",
      "Epoch 12\n",
      "52596/52596 [==============================] - 32s - loss: 0.4410 - acc: 0.8253 - val_loss: 0.4988 - val_acc: 0.8060\n",
      "Epoch 13\n",
      "52596/52596 [==============================] - 32s - loss: 0.4408 - acc: 0.8238 - val_loss: 0.4959 - val_acc: 0.8075\n",
      "Epoch 14\n",
      "52596/52596 [==============================] - 36s - loss: 0.4390 - acc: 0.8245 - val_loss: 0.4959 - val_acc: 0.8051\n",
      "Epoch 15\n",
      "52596/52596 [==============================] - 37s - loss: 0.4383 - acc: 0.8264 - val_loss: 0.4973 - val_acc: 0.8067\n",
      "Epoch 16\n",
      "52596/52596 [==============================] - 34s - loss: 0.4327 - acc: 0.8263 - val_loss: 0.5061 - val_acc: 0.8055\n",
      "Epoch 17\n",
      "52596/52596 [==============================] - 32s - loss: 0.4308 - acc: 0.8291 - val_loss: 0.4943 - val_acc: 0.8081\n",
      "Epoch 18\n",
      "52596/52596 [==============================] - 34s - loss: 0.4296 - acc: 0.8285 - val_loss: 0.4971 - val_acc: 0.8097\n",
      "Epoch 19\n",
      "52596/52596 [==============================] - 33s - loss: 0.4280 - acc: 0.8296 - val_loss: 0.4959 - val_acc: 0.8107\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e0c1baab8e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"otto1.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training model...\")\n",
    "\n",
    "model.fit(X, y, nb_epoch=20, batch_size=128, validation_split=0.15,show_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission...\n",
      "144368/144368 [==============================] - 12s    \n",
      "Wrote submission to file keras-otto.csv.\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"otto1.hdf5\",overwrite=True)\n",
    "f = h5py.File('otto1.hdf5','r')\n",
    "print(\"Generating submission...\")\n",
    "\n",
    "proba = model.predict_proba(X_test)\n",
    "make_submission(proba, ids, encoder, fname='keras-otto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
