{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import math\n",
    "import ast\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "'''\n",
    "    This demonstrates how to reach a score of 0.4890 (local validation)\n",
    "    on the Kaggle Otto challenge, with a deep net using Keras.\n",
    "    Compatible Python 2.7-3.4. Requires Scikit-Learn and Pandas.\n",
    "    Recommended to run on GPU: \n",
    "        Command: THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python kaggle_otto_nn.py\n",
    "        On EC2 g2.2xlarge instance: 19s/epoch. 6-7 minutes total training time.\n",
    "    Best validation score at epoch 21: 0.4881 \n",
    "    Try it at home:\n",
    "        - with/without BatchNormalization (BatchNormalization helps!)\n",
    "        - with ReLU or with PReLU (PReLU helps!)\n",
    "        - with smaller layers, largers layers\n",
    "        - with more layers, less layers\n",
    "        - with different optimizers (SGD+momentum+decay is probably better than Adam!)\n",
    "    Get the data from Kaggle: https://www.kaggle.com/c/otto-group-product-classification-challenge/data\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(path, train=True):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    if train:\n",
    "        np.random.shuffle(X)  # https://youtu.be/uyUXoap67N8\n",
    "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "        return X, labels\n",
    "    else:\n",
    "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "        return X, ids\n",
    "\n",
    "\n",
    "def preprocess_data(X, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    return X, scaler\n",
    "\n",
    "\n",
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "    return y, encoder\n",
    "\n",
    "\n",
    "def make_submission(y_prob, ids, encoder, fname):\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('id,')\n",
    "        f.write(','.join([str(i) for i in encoder.classes_]))\n",
    "        f.write('\\n')\n",
    "        for i, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([i] + [str(p) for p in probs.tolist()])\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 classes\n",
      "93 dims\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "X, labels = load_data('train.csv', train=True)\n",
    "X, scaler = preprocess_data(X)\n",
    "y, encoder = preprocess_labels(labels)\n",
    "\n",
    "X_test, ids = load_data('test.csv', train=False)\n",
    "X_test, _ = preprocess_data(X_test, scaler)\n",
    "\n",
    "nb_classes = y.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X.shape[1]\n",
    "print(dims, 'dims')\n",
    "\n",
    "\n",
    "print(\"Building model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array = np.loadtxt(\"input_array.csv\")\n",
    "output_array = np.loadtxt(\"output_array.csv\")\n",
    "\n",
    "num_floors = int(np.ptp(output_array[:, 0], axis=0) + 1)\n",
    "\n",
    "iden_mat = np.eye(num_floors, dtype=int)\n",
    "binarized_output_array = []\n",
    "for floor in output_array[:, 0]:\n",
    "    binarized_output_array.append(iden_mat[int(floor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "mean_center_scale = 0.5\n",
    "X = (-mean_center_scale + 2*mean_center_scale*(input_array - np.min(input_array))/float(np.ptp(input_array)))\n",
    "y = np.asarray(binarized_output_array)\n",
    "\n",
    "print(y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], 250, init='glorot_normal'))\n",
    "# model.add(PReLU((512,)))\n",
    "model.add(Activation('tanh'))\n",
    "# model.add(BatchNormalization((512,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "# model.add(PReLU((512,)))\n",
    "# model.add(BatchNormalization((512,)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(512, 512, init='glorot_uniform'))\n",
    "# model.add(PReLU((512,)))\n",
    "# model.add(BatchNormalization((512,)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(250, 4, init='glorot_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0004 - acc: 1.0000     \n",
      "Epoch 2/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0004 - acc: 1.0000     \n",
      "Epoch 3/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "3582/3582 [==============================] - 1s - loss: 0.0003 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b095690>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "\n",
    "# batch_size=128, validation_split=0.15\n",
    "\n",
    "model.fit(X, y, nb_epoch=10, show_accuracy=True)\n",
    "# model.train_on_batch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582/3582 [==============================] - 0s     \n",
      "[[  9.29960823e-04   4.55543153e-03   8.81465149e-01   1.13049459e-01]\n",
      " [  9.29960823e-04   4.55543153e-03   8.81465149e-01   1.13049459e-01]\n",
      " [  4.16154954e-04   2.88406250e-03   9.81641298e-01   1.50584843e-02]\n",
      " ..., \n",
      " [  3.03535377e-04   9.99585184e-01   8.93365070e-05   2.19437944e-05]\n",
      " [  3.03535377e-04   9.99585184e-01   8.93365070e-05   2.19437944e-05]\n",
      " [  1.08939053e-03   9.98473812e-01   3.69948793e-04   6.68487662e-05]]\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict_proba(X)\n",
    "print(proba)\n",
    "# make_submission(proba, ids, encoder, fname='keras-otto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.42564689e-06   1.98431562e-01   2.21497101e-01   5.78015024e-01\n",
      "   3.34626706e-11   2.87196675e-06   2.05075527e-03   2.28725031e-07\n",
      "   3.04342314e-08]\n"
     ]
    }
   ],
   "source": [
    "print(proba[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"test3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('test.hdf5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"test.hdf5\" (mode r)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0\n",
      "<HDF5 group \"/layer_0\" (2 members)>\n",
      "layer_1\n",
      "<HDF5 group \"/layer_1\" (0 members)>\n",
      "layer_2\n",
      "<HDF5 group \"/layer_2\" (2 members)>\n",
      "layer_3\n",
      "<HDF5 group \"/layer_3\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "for fin,fkey in f.iteritems():\n",
    "    print(fin)\n",
    "    print(fkey)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/layer_0\" (2 members)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.name\n",
    "f['layer_0']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0\n",
      "layer_0/param_0\n",
      "layer_0/param_1\n",
      "layer_1\n",
      "layer_2\n",
      "layer_2/param_0\n",
      "layer_2/param_1\n",
      "layer_3\n"
     ]
    }
   ],
   "source": [
    "f.visit(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0 <HDF5 group \"/layer_0\" (2 members)>\n",
      "layer_0/param_0 <HDF5 dataset \"param_0\": shape (541, 250), type \"<f8\">\n",
      "layer_0/param_1 <HDF5 dataset \"param_1\": shape (250,), type \"<f8\">\n",
      "layer_1 <HDF5 group \"/layer_1\" (0 members)>\n",
      "layer_2 <HDF5 group \"/layer_2\" (2 members)>\n",
      "layer_2/param_0 <HDF5 dataset \"param_0\": shape (250, 4), type \"<f8\">\n",
      "layer_2/param_1 <HDF5 dataset \"param_1\": shape (4,), type \"<f8\">\n",
      "layer_3 <HDF5 group \"/layer_3\" (0 members)>\n"
     ]
    }
   ],
   "source": [
    "f.visititems(lambda name,obj:print(name, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.90197961e-03   1.18766944e-02   2.40259374e-03  -3.56830892e-03\n",
      "  -1.29862597e-02  -1.64156936e-05  -1.34127999e-04  -4.55241356e-03\n",
      "   2.21322759e-03  -4.47395665e-03  -2.22056617e-03  -5.70677936e-03\n",
      "  -6.10961176e-04   6.19648562e-03   1.88218657e-03  -9.00871802e-03\n",
      "   8.28027491e-04  -1.91418119e-04  -1.75501312e-03   6.71617942e-05\n",
      "   3.61379984e-03  -5.52694515e-04   4.73527548e-03  -8.57505648e-03\n",
      "  -1.73284098e-03   1.29134331e-03  -1.18414024e-03  -3.27039478e-03\n",
      "  -1.60713380e-03   1.78908248e-03   6.67603857e-04   1.02940916e-03\n",
      "   3.39556222e-04  -9.01556729e-04   4.98067540e-03  -9.90481648e-04\n",
      "   7.43468951e-03  -6.67229799e-03  -7.03490331e-03   3.01043442e-03\n",
      "   2.42478874e-04   6.63993751e-03  -5.18203854e-03   3.39509949e-03\n",
      "   1.44741881e-03   3.82907100e-03   3.23554482e-03   1.45010590e-03\n",
      "   6.01245762e-03   6.71767367e-03  -3.17853818e-03   1.40380215e-03\n",
      "   1.13291908e-03  -4.50581454e-03   9.93930846e-04  -1.38145228e-03\n",
      "  -8.67824368e-05   1.04442368e-03   2.47400622e-04  -8.73746263e-04\n",
      "  -3.06124217e-03  -4.22417138e-03   2.69658280e-03   5.22669720e-03\n",
      "  -3.13416637e-03   1.01687159e-03  -5.30810812e-03   5.77379938e-03\n",
      "   7.32896066e-03  -2.63100318e-03  -2.26317765e-03   5.28933355e-03\n",
      "   3.70209481e-03  -1.71952216e-03   5.66484941e-04  -5.93043349e-04\n",
      "   1.87812013e-03  -2.18632505e-03   1.66116993e-03  -2.31816236e-03\n",
      "  -3.03816792e-04  -6.60534891e-03  -1.30333371e-04   1.07462321e-03\n",
      "   2.38025543e-03   3.08184882e-03  -2.59025770e-03  -1.29785508e-04\n",
      "   8.20376540e-04  -4.76971014e-04  -2.01103193e-04   2.29351438e-03\n",
      "  -5.02322617e-03  -1.59755620e-03   1.68572309e-03  -5.74776800e-03\n",
      "   3.62275913e-03   3.65055683e-03   1.62512069e-04  -8.23657974e-03\n",
      "   1.96630799e-04   4.16207082e-03   3.98517394e-03   4.21264160e-03\n",
      "   5.13484043e-04  -8.80199483e-03  -4.45443347e-04   5.34267845e-03\n",
      "  -1.01820612e-03  -1.15598335e-03  -8.53244423e-04  -1.27283988e-03\n",
      "   4.61852208e-03  -2.75304703e-04   1.99525777e-03  -1.13863267e-03\n",
      "   5.16709402e-04  -3.48079539e-03   5.25273031e-03   5.00300615e-03\n",
      "  -1.41881978e-03  -4.30839769e-03   5.50181136e-03   3.61038736e-03\n",
      "  -7.98997298e-03   1.42716144e-03   5.61732469e-03  -3.03504190e-03\n",
      "  -2.02887346e-04   3.58235242e-03  -2.33510161e-03  -6.83677894e-05\n",
      "  -3.12204532e-03  -2.97746119e-03   1.64024594e-03   4.08395645e-03\n",
      "  -5.72925393e-03   4.30984831e-03  -2.27934349e-03  -1.07094615e-02\n",
      "  -5.76457591e-03   4.96613193e-04  -3.57555067e-03   1.41524963e-03\n",
      "  -4.26888290e-05  -3.39411972e-03  -3.34758584e-03   2.37382129e-03\n",
      "   5.53239803e-03   3.99096918e-03  -3.51513318e-04   3.92170585e-03\n",
      "   1.73919679e-04  -3.72173722e-03  -8.58789140e-04  -9.59748992e-04\n",
      "   4.24095660e-04   1.34000926e-03  -2.54719184e-03   8.78937929e-04\n",
      "  -6.41001763e-03   4.82172067e-03  -1.33852335e-03  -6.73174657e-04\n",
      "  -7.28841907e-03   6.57600460e-03  -1.40928115e-03  -9.86697408e-05\n",
      "   2.26325637e-03  -4.87495176e-03  -4.62592007e-03  -2.78424049e-03\n",
      "  -1.81924521e-03   2.85973510e-03  -4.34245738e-03  -2.65285995e-03\n",
      "   4.67134720e-03   9.36651325e-04  -2.02233869e-05  -5.99940198e-03\n",
      "   8.93205726e-04   8.74220266e-03   4.42182882e-04  -8.05424033e-03\n",
      "  -2.46434150e-04  -3.27934761e-03  -8.77242801e-04  -1.27373380e-03\n",
      "   3.60414531e-04   6.78580005e-03   2.91946484e-03  -3.78399844e-04\n",
      "  -8.85128256e-04  -4.77411879e-03   4.04196762e-03  -6.71758016e-03\n",
      "   7.98840916e-03  -5.16369090e-03  -2.02998233e-03   4.37138805e-04\n",
      "   7.64115961e-04   1.47824122e-02  -1.77331534e-03  -2.25754458e-03\n",
      "   7.61418248e-03  -2.09325766e-03   7.56012235e-03  -8.76254217e-04\n",
      "  -1.77303050e-03  -4.78353802e-03  -8.71524802e-04  -6.35209448e-03\n",
      "   1.83342834e-03   9.61948433e-04   1.65349401e-03  -2.43441676e-04\n",
      "   1.92718472e-03  -4.86365418e-03  -8.92681260e-04  -6.52693357e-03\n",
      "  -3.68243478e-03   3.03291205e-03   1.77852228e-03  -1.23173288e-02\n",
      "   1.86691601e-04   4.31776527e-03  -3.52270834e-03   3.83146612e-03\n",
      "   3.34322771e-03  -4.31999975e-03   1.72521529e-03   4.42653778e-03\n",
      "  -1.69072063e-03  -1.67173866e-03   5.91294830e-03  -5.46277901e-03\n",
      "   3.64434804e-03   1.52369791e-03   3.90270414e-03  -1.13240637e-03\n",
      "   2.26309743e-03   2.27691632e-03   6.01962713e-04  -4.07875666e-03\n",
      "   9.04059251e-03   3.05416753e-04  -5.35138916e-03  -7.56167081e-04\n",
      "  -6.04328823e-03  -1.90616612e-04]\n"
     ]
    }
   ],
   "source": [
    "# create a sparse array from the sample/matrix group\n",
    "data = f['layer_0/param_1'].value\n",
    "# indices = f['sample/matrix/indices'].value\n",
    "# indptr = f['sample/matrix/indptr'].value\n",
    "# sample = sp.csr_matrix((data,indices,indptr))\n",
    "# display as a dense array\n",
    "# print(sample.A)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initializing the weights\n",
    "\n",
    "num_input = 541\n",
    "num_output = 4\n",
    "num_hidden = 1000\n",
    "\n",
    "w1 = np.asarray(rng.uniform(\n",
    "    low=-np.sqrt(6./(num_input + num_hidden)),\n",
    "    high=np.sqrt(6./(num_input + num_hidden)),\n",
    "    size=(num_input, num_hidden)\n",
    "    \n",
    "))\n",
    "\n",
    "w2 = np.asarray(rng.uniform(\n",
    "    low=-np.sqrt(6./(num_hidden + num_output)),\n",
    "    high=np.sqrt(6./(num_hidden + num_output)),\n",
    "    size=(num_hidden, num_output)\n",
    "    \n",
    "))\n",
    "\n",
    "#initializing the bias vectors\n",
    "\n",
    "b1 = np.asarray(rng.uniform(\n",
    "    low=-1.,\n",
    "    high=1.,\n",
    "    size=(1, num_hidden)\n",
    "    \n",
    "))\n",
    "\n",
    "b2 = np.asarray(rng.uniform(\n",
    "    low=-1.,\n",
    "    high=1.,\n",
    "    size=(1, num_output)\n",
    "    \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 300\n",
    "input = np.asarray(input_array[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_array = np.loadtxt(\"input_array.csv\")\n",
    "output_array = np.loadtxt(\"output_array.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "time taken to execute the code: 0.0398778915405 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "mean_center_scale = 0.5\n",
    "input = (-mean_center_scale + 2*mean_center_scale*(input - np.min(input))/float(np.ptp(input)))\n",
    "#calculating the output of the hidden layer\n",
    "\n",
    "z1= input.dot(w1) + b1\n",
    "a1 = np.tanh(z1)\n",
    "#calculating the output of the output layer\n",
    "\n",
    "z2 = a1.dot(w2) + b2\n",
    "\n",
    "#softmax function\n",
    "exp_scores = np.exp(z2)\n",
    "probs = exp_scores/np.sum(exp_scores)\n",
    "print(np.argmax(probs))\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"time taken to execute the code:\", (end_time - start_time), \"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2.  791.  139.]\n"
     ]
    }
   ],
   "source": [
    "index = 300\n",
    "print(output_array[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"weight1.csv\", w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
